{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUymE2l9GZfO"
      },
      "source": [
        "**Copyright 2023 Google LLC.**\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "JMyTNwSJGGWg"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img align=\"left\" width=\"150\" src=\"https://services.google.com/fh/files/misc/ml_toast_logo.png\" alt=\"ml_toast_logo\"></img><br/><br/>\n",
        "\n",
        "# ðŸž ML-ToAST: **M**ulti**l**ingual **To**pic Clustering of **A**ds-triggering **S**earch **T**erms"
      ],
      "metadata": {
        "id": "wSdRBuDb7jfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Disclaimer: This is not an official Google product.**\n",
        "\n",
        "**ML-ToAST** is an open-source tool that helps users cluster multilingual search terms captured from different time windows into semantically relevant topics. It helps advertisers / marketers surface the topics or *themes* their audience are interested in, so that they can tailor their marketing activities accordingly.\n",
        "\n",
        "Under the hood, the tool relies on Google's [Universal Sentence Encoder Multilingual](https://tfhub.dev/google/universal-sentence-encoder-multilingual/3) model to generate word embeddings, applies a couple of widely-used clustering algorithms - namely [K-Means](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/compat/v1/estimator/experimental/KMeans) and [HDBSCAN](https://hdbscan.readthedocs.io/en/latest/index.html) (with [UMAP](https://umap-learn.readthedocs.io/en/latest/) dimensionality reduction) - to generate clusters, and then selects the most meaningful term(s) to represent each cluster.\n",
        "\n",
        "Input is provided via a Google Sheets spreadsheet, preprocessing and clustering takes place directly in this notebook, and the resulting topics are output back into the same spreadsheet. In other words, all data remains **private** - only visible to and in the control of the tool's user.\n",
        "\n",
        "Though the samples provided here are specific to Google Ads, the logic can quite seamlessly be tweaked to work with any other advertising platform."
      ],
      "metadata": {
        "id": "2aYXRT3tCxJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ],
      "metadata": {
        "id": "t7NhzM_GcpHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenges\n",
        "\n",
        "Advertisers spend a significant amount of time analyzing how customers are searching for and engaging with their business, in order to understand:\n",
        "\n",
        "* Where their existing offerings resonate most; and\n",
        "* How they can tailor facets of their ads, such as landing pages and creatives, to match changing consumer interest.\n",
        "\n",
        "One of the approaches advertisers rely on is analyzing search queries against which their ads appear, categorising these queries into meaningful themes, and analyzing themes to generate insights.\n",
        "\n",
        "> ***Topic clustering requires both time and expertise to execute properly, and may be computationally resource intensive.***\n",
        "\n",
        "In the context of Google Ads, the [Search Terms report](https://support.google.com/google-ads/answer/2472708) for a particular account lists all the search queries that have triggered the ads defined in that account, along with performance metrics (such as clicks, impressions, etc.). It is important to note that certain search terms that don't have enough query activity are omitted from the report in order to maintain Google's standards on data privacy.\n",
        "\n",
        "> ***Google Ads: though the [Search Terms report](https://support.google.com/google-ads/answer/2472708) can be downloaded and analyzed, it is cumbersome for advertisers to sift through thousands of queries - usually in multiple languages - to extract meaningful insights.***\n",
        "\n",
        "Google Ads employs several different [search automation](https://services.google.com/fh/files/misc/unlock_the_power_of_search_2022.pdf) and optimization features, one of which is Broad Match (BM). Whereas other keyword matching types focus only on syntax, [Broad Match](https://support.google.com/google-ads/answer/12159290) applies matching based on semantics - the meaning conveyed by a search - in addition to syntax. BM also looks at additional signals in the account - which include landing pages, keywords in ad groups, previous searches, and more - in order to match more relevant traffic.\n",
        "\n",
        "> ***Google Ads: the need to understand changing user interest is becoming ever more important, particularly with automated search optimization (e.g. [Broad Match](https://support.google.com/google-ads/answer/12159290)) becoming more fundamental.***\n",
        "\n",
        "Google Ads also provides [search term insights](https://support.google.com/google-ads/answer/11386930) within its user interface (UI). Search terms that triggered ads over the past 56 days are automatically analyzed and grouped into categories and subcategories, including performance metrics.\n",
        "\n",
        "> ***Google Ads: [search term insights](https://support.google.com/google-ads/answer/11386930) - though technologically more sophisticated than the methodology applied here - cover the past 8 weeks only, are not available beyond the UI, and cannot be collated across accounts.***"
      ],
      "metadata": {
        "id": "GVt9pmm4xQUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introducing ML-ToAST\n",
        "\n",
        "ML-ToAST tackles the challenges mentioned above in a simple, configurable and privacy-safe way. It relies on a Google Sheets spreadsheet as input, where search terms from different lookback windows can be compared (see the ***Which search terms to extract?*** section below for more information) to uncover only those that are *new*, and/or also those that have not received enough impressions (configurable - defaults to 1000). This represents the corpus of search terms that can be further analyzed and categorized into semantically relevant topics.\n",
        "\n",
        "Additional input groups pertaining to Google Ads Broad Match (BM) are also built and analyzed to shed some light into BM's performance.\n",
        "\n",
        "The figure below provides an overview of the core functionality of ML-ToAST.\n"
      ],
      "metadata": {
        "id": "6r94niV-EdoL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://services.google.com/fh/files/misc/ml_toast_diagram.png\" alt=\"ml_toast_diagram\"></img><br>\n",
        "Fig. 1. ML-ToAST Process Diagram\n",
        "</center>"
      ],
      "metadata": {
        "id": "tJ4BeqVVYRmp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Which search terms to extract?\n",
        "\n",
        "We recommend extracting the Google Ads [Search Terms report](https://support.google.com/google-ads/answer/2472708) for the following periods:\n",
        " * **Last 30 days** (e.g. Nov 1 - Nov 30): it generally makes sense to look at the most recent search terms that triggered your ads.\n",
        " * **Previous 30/31 days** (e.g. Oct 1 - Oct 31): this helps provide information on those search terms that constitute your core business over those that are recently trending.\n",
        " * **Last 30 days last year** (e.g. Nov 1 - Nov 30 of the previous year): to account for seasonality effects (e.g. holiday season).\n",
        "\n",
        "We also recommend restricting the extracted search terms to a subset of *related* campaigns (e.g. all campaigns for a specific *product line* or *operating domain*) rather than all campaigns in your account. This allows the models applied here to better capture how the search terms relate to one another, and therefore, extract more meaningful topics.\n",
        "\n",
        "The report can be downloaded from the Google Ads UI in CSV format and imported into a Google Sheets spreadsheet.\n",
        "\n",
        "*Note: if you have multiple accounts operating under the same product line or domain, you can extract search terms from those accounts as well and group them all into the same Google Sheets spreadsheet.*"
      ],
      "metadata": {
        "id": "Um6l3f0Rjm76"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Started"
      ],
      "metadata": {
        "id": "YZNnFN1XFz9V"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krUBtMJeAQlf",
        "cellView": "form"
      },
      "source": [
        "#@title Authenticate your user for this colab session\n",
        "import logging\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "logging.getLogger().setLevel(logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns6MdB_5OaZ8",
        "cellView": "form"
      },
      "source": [
        "#@title Install dependencies\n",
        "!pip install tensorflow-text hdbscan umap-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input and Preprocessing\n"
      ],
      "metadata": {
        "id": "OJb_S6X0ILa2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ywOMopb0gUu",
        "cellView": "form"
      },
      "source": [
        "#@title Configurable params { run: 'auto' }\n",
        "\n",
        "#@markdown Enter your spreadsheet ID:\n",
        "spreadsheet_id = \"id-goes-here\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the main worksheet name (which should usually contain the search terms from the last month):\n",
        "input_sheet_name = \"colab-input-main\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the prefix for any additional worksheets you would also like to analyze (e.g. search terms of the previous month, previous year, etc.):\n",
        "additional_sheets_prefix = \"colab-input-lookback-\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the name of the column that contains search terms. This value should be the same across all worksheets:\n",
        "search_terms_column = \"Search term\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown <hr>Filtering settings\n",
        "\n",
        "#@markdown ***Check*** the checkbox to filter on new terms (i.e. compare search terms from the aforementioned lookback worksheets) and leave ***unchecked*** to analyze search terms from the main worksheet only.\n",
        "filter_new_terms = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Enter the name of a column that contains a metric you would like to use for filtering (e.g. impressions):\n",
        "filter_metric_column = \"Impr.\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Set this to filter terms with a *metric* (e.g. impression) value lower than the input. Set to *-1* to skip filtering.\n",
        "filter_metric_max_threshold = 1000 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Select the desired logical grouping (AND/OR) of the filters:\n",
        "filters_grouping = \"AND\" #@param [\"AND\", \"OR\"]\n",
        "\n",
        "#@markdown <hr>Advanced settings\n",
        "\n",
        "#@markdown Enter a comma-separated list of *stop words* which should be excluded from all generated topics:\n",
        "stop_words = \"stop1, stop2\" #@param {type:\"string\"}\n",
        "\n",
        "if stop_words:\n",
        "  stop_words = stop_words.replace(', ', ',').split(',')\n",
        "else:\n",
        "  stop_words = None\n",
        "\n",
        "#@markdown ***Check*** the checkbox to perform hyperparameter tuning for UMAP + HDBSCAN (increases processing time by a factor of ~3). Leave ***unchecked*** to use the default clustering parameters.\n",
        "hyperparameter_tuning = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Google Ads specific params\n",
        "match_type_column = \"Match type\"\n",
        "match_type_broad = \"Broad match\"\n",
        "all_report_metrics = ['Clicks', 'Impr.', 'Cost']\n",
        "\n",
        "# Validation rules\n",
        "if not spreadsheet_id or not input_sheet_name or not search_terms_column:\n",
        "  raise ValueError(\n",
        "      'Invalid input! Please make sure at least '\n",
        "      '\"spreadsheet_id\", \"input_sheet_name\" and \"search_terms_column\" '\n",
        "      'are provided.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC8BrKCh0QOC",
        "cellView": "form"
      },
      "source": [
        "#@title Fetch data from the input spreadsheet\n",
        "#@markdown The first row in each worksheet will be considered the **column headers** row.\n",
        "import pandas as pd\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "creds, _ = default()\n",
        "sheets_client = gspread.authorize(creds)\n",
        "spreadsheet = sheets_client.open_by_key(spreadsheet_id)\n",
        "\n",
        "input_values = spreadsheet.worksheet(input_sheet_name).get_all_values()\n",
        "additional_sheets_values = []\n",
        "\n",
        "if filter_new_terms and additional_sheets_prefix:\n",
        "  for sheet in spreadsheet.worksheets():\n",
        "    if sheet.title.startswith(additional_sheets_prefix):\n",
        "      additional_sheets_values.append(sheet.col_values(1))\n",
        "\n",
        "input_pd = pd.DataFrame(input_values[1:], columns=input_values[0])\n",
        "\n",
        "for report_metric in all_report_metrics:\n",
        "  input_pd[report_metric] = pd.to_numeric(\n",
        "      input_pd[report_metric].str.replace(',', ''))\n",
        "\n",
        "print(\n",
        "    f'Worksheet: {input_sheet_name}\\nNumber of rows: {len(input_pd)}\\n'\n",
        "    'First 5 rows:')\n",
        "input_pd.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extract search terms and apply the defined filters\n",
        "\n",
        "def add_filter(existing_filter, new_filter):\n",
        "  if filters_grouping == 'AND':\n",
        "    return existing_filter & new_filter\n",
        "  return existing_filter | new_filter\n",
        "\n",
        "dfs = [\n",
        "    pd.DataFrame(sheet_values[1:], columns=[sheet_values[0]])\n",
        "    for sheet_values in additional_sheets_values]\n",
        "\n",
        "data_unfiltered = input_pd.copy()\n",
        "\n",
        "series_filter = (filters_grouping == 'AND')\n",
        "applied_filters = []\n",
        "\n",
        "if dfs:\n",
        "  data_unfiltered = (\n",
        "      data_unfiltered.merge(pd.concat(dfs).drop_duplicates(),\n",
        "                    on=search_terms_column,\n",
        "                    how='left',\n",
        "                    indicator=True))\n",
        "  series_filter = add_filter(\n",
        "      existing_filter=series_filter, new_filter=(\n",
        "          data_unfiltered['_merge'] == 'left_only'))\n",
        "  applied_filters.append('filter_new_terms')\n",
        "\n",
        "if filter_metric_column and filter_metric_max_threshold > 0:\n",
        "  series_filter = add_filter(\n",
        "      existing_filter=series_filter, new_filter=(\n",
        "      data_unfiltered[filter_metric_column] <= filter_metric_max_threshold))\n",
        "  applied_filters.append(\n",
        "      f'filter_metric_max_threshold < {filter_metric_max_threshold}')\n",
        "\n",
        "filtered_data = (\n",
        "    data_unfiltered[series_filter] if applied_filters else data_unfiltered)\n",
        "\n",
        "if '_merge' in filtered_data.columns:\n",
        "  filtered_data = filtered_data.drop(columns='_merge')\n",
        "\n",
        "if filter_metric_column:\n",
        "  filtered_data = filtered_data.sort_values(\n",
        "      by=filter_metric_column, ascending=False)\n",
        "\n",
        "print('\\n'.join([\n",
        "    f'Filtered data - total number of rows: {len(filtered_data)}',\n",
        "    f'Filters applied: {applied_filters}',\n",
        "    (\n",
        "        f\"Filters logical grouping: '{filters_grouping}'\"\n",
        "        if len(applied_filters) > 1 else ''),\n",
        "    'First 5 rows:']))\n",
        "filtered_data.head()"
      ],
      "metadata": {
        "id": "xD4cB0YElXtu",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extract 'Broad Match' terms from the main worksheet\n",
        "all_broad_match = input_pd.copy()\n",
        "all_broad_match = all_broad_match[\n",
        "    input_pd[match_type_column] == match_type_broad]\n",
        "\n",
        "if filter_metric_column:\n",
        "  all_broad_match = all_broad_match.sort_values(\n",
        "      by=filter_metric_column, ascending=False)\n",
        "broad_match_groups = {'all_broad_match_terms': all_broad_match}\n",
        "\n",
        "print(\n",
        "    'Extracted:\\n'\n",
        "    f' - All terms where \"{match_type_column}\" is \"{match_type_broad}\" '\n",
        "    f'from {input_sheet_name}. Number of rows: {len(all_broad_match)}')"
      ],
      "metadata": {
        "id": "BisYiJXWlyM_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Topic Clustering"
      ],
      "metadata": {
        "id": "aphRjaaviXKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import the topic clustering library\n",
        "!echo \"Restoring working directory to root...\"\n",
        "%cd /content\n",
        "!rm -rf ml_toast \u0026\u0026 git clone https://github.com/google/ml_toast.git\n",
        "!echo \"Changing working directory to ml_toast...\"\n",
        "%cd ml_toast\n",
        "\n",
        "from ml_toast import topic_clustering as topic_clustering_lib"
      ],
      "metadata": {
        "id": "mtoxiM9RyVaV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Use the library to determine topics for all input groups\n",
        "terms_pds = {'filtered_terms': filtered_data}\n",
        "for key, broad_match_group in broad_match_groups.items():\n",
        "  terms_pds[key] = broad_match_group\n",
        "\n",
        "for key, terms_pd in terms_pds.items():\n",
        "  topic_clustering = topic_clustering_lib.TopicClustering(\n",
        "      data_id=key,\n",
        "      input_col=search_terms_column,\n",
        "      stop_words=stop_words,\n",
        "      do_hdbscan_hyperopt=hyperparameter_tuning)\n",
        "  topics_kmeans, topics_hdbscan = topic_clustering.determine_topics(terms_pd)\n",
        "  terms_pd['Topic'] = topics_kmeans\n",
        "  terms_pd['Additional Topics'] = topics_hdbscan"
      ],
      "metadata": {
        "id": "qcgsRGcg0maR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output"
      ],
      "metadata": {
        "id": "DZupJfkwIHml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extract performance metrics for the generated topics\n",
        "metrics_pds = {}\n",
        "\n",
        "for key, terms_pd in terms_pds.items():\n",
        "  for topics_type in ['Topic', 'Additional Topics']:\n",
        "    cluster_metrics = pd.DataFrame()\n",
        "    cluster_metrics['Topic'] = terms_pd[topics_type]\n",
        "    for report_metric in all_report_metrics:\n",
        "      cluster_metrics[report_metric] = terms_pd[report_metric]\n",
        "\n",
        "    cluster_metrics = cluster_metrics.groupby(by='Topic', sort=False).agg(\n",
        "        ['mean', 'median', 'min', 'max', 'std', 'var'])\n",
        "    cluster_metrics.insert(loc=0, column='Topic', value=cluster_metrics.index)\n",
        "    cluster_metrics.insert(\n",
        "        loc=1,\n",
        "        column='Count',\n",
        "        value=terms_pd.groupby(by=topics_type, sort=False).count()[\n",
        "            search_terms_column])\n",
        "    cluster_metrics = cluster_metrics.sort_values(by='Count', ascending=False)\n",
        "\n",
        "    metrics_pds[\n",
        "        f\"{key}_{topics_type.lower().replace(' ', '_')}\"] = cluster_metrics"
      ],
      "metadata": {
        "id": "OKiC0B2u2D61",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Write results back to the input spreadsheet\n",
        "#@markdown New worksheets with the prefix **colab-** will be appended to the spreadsheet,\n",
        "#@markdown or overwritten if they already exist.\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "\n",
        "for key, terms_pd in terms_pds.items():\n",
        "  try:\n",
        "    output_sheet = spreadsheet.worksheet(f'colab-{key}-output')\n",
        "    output_sheet.clear()\n",
        "  except gspread.exceptions.WorksheetNotFound:\n",
        "    output_sheet = spreadsheet.add_worksheet(\n",
        "        f'colab-{key}-output', rows=len(terms_pd), cols=len(terms_pd.columns))\n",
        "\n",
        "  set_with_dataframe(output_sheet, terms_pd, include_column_header=True)\n",
        "\n",
        "for key, metrics_pd in metrics_pds.items():\n",
        "  try:\n",
        "    metrics_sheet = spreadsheet.worksheet(f'colab-{key}-metrics')\n",
        "    metrics_sheet.clear()\n",
        "  except gspread.exceptions.WorksheetNotFound:\n",
        "    metrics_sheet = spreadsheet.add_worksheet(\n",
        "        f'colab-{key}-metrics',\n",
        "        rows=len(metrics_pd),\n",
        "        cols=len(metrics_pd.columns))\n",
        "  set_with_dataframe(metrics_sheet, metrics_pd, include_column_header=True)"
      ],
      "metadata": {
        "id": "UEs6V8SS4xSb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the generated topics in LookerStudio\n",
        "\n",
        "ML-Toast provides a template LookerStudio dashboard to help you visualize the generated topics and quickly surface insights.\n",
        "\n",
        "Use [this link](https://datastudio.google.com/c/u/0/reporting/df12a39a-eab3-448e-9ce2-854c05335786/page/RRIAD/preview) to create a copy of the dashboard and get started! All you would need to do is map the data sources used by the dashboard to the spreadsheet used for the input / output above."
      ],
      "metadata": {
        "id": "0l-ceTbYbfV-"
      }
    }
  ]
}
